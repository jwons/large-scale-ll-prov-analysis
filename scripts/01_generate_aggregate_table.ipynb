{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "quarterly-bleeding",
   "metadata": {},
   "source": [
    "# Preprocessing for Analysis of Large-Scale Collection of Language-Level Provenance\n",
    "\n",
    "Using the service [RaaS](https://www.github.com/jwons/raas), we executed thousands of R scripts hosted on Harvard's Dataverse while collecting langauge-level provenance using the `rdtLite` variant of the [RDataTracker](https://www.github.com/End-to-end-provenance/RDataTracker) collection tool. This notebook takes that raw data and processes it to generate an aggregate table of information about all the scripts to help find trends and patterns in R scripts or their provenance. \n",
    "\n",
    "## Description of Raw Data\n",
    "\n",
    "The RaaS collection process resulted in ~100 GB of metadata we have stored in a directory ll-prov-data (not hosted on GitHub due to size). The directory structure is described below:\n",
    "```\n",
    "ðŸ“¦ll-prov-data\n",
    " â”£ ðŸ“‚dataset_name1_prov_data\n",
    " â”ƒ â”— ðŸ“‚prov_data\n",
    " â”ƒ â”ƒ â”£ ðŸ“‚dataset1_script_name1\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚data\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚debug\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚scripts\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”— ðŸ“œdataset1_script_name1.R\n",
    " â”ƒ â”ƒ â”ƒ â”— ðŸ“œprov.json\n",
    " â”ƒ â”ƒ â”£ ðŸ“‚dataset1_script_name2\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚data\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”£ ðŸ“œrecorded_text_data.txt\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”£ ðŸ“œrecorded_csv_data.csv\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚debug\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚scripts\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”— ðŸ“œdataset1_script_name2.R\n",
    " â”ƒ â”ƒ â”ƒ â”— ðŸ“œprov.json\n",
    " â”ƒ â”ƒ â”£ ðŸ“œget_prov.RData\n",
    " â”ƒ â”ƒ â”— ðŸ“œrun_log.csv\n",
    " â”£ ðŸ“‚dataset_name2_prov_data\n",
    " â”ƒ â”— ðŸ“‚prov_data\n",
    " â”ƒ â”ƒ â”£ ðŸ“‚dataset2_script_name1\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚data\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚debug\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚scripts\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”— ðŸ“œdataset2_script_name1.R\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”— ðŸ“œsourced_script.R \n",
    " â”ƒ â”ƒ â”ƒ â”— ðŸ“œprov.json\n",
    " â”ƒ â”ƒ â”£ ðŸ“œget_prov.RData\n",
    " â”ƒ â”ƒ â”— ðŸ“œrun_log.csv\n",
    " ```\n",
    " Dataverse hosts 'datasets' which contain artifacts from published research, in this context that means one or more scripts. Our raw data is split into this granularity, with a directory for the provenance of each dataset (e.g. `dataset_name1_prov_data`). Within the dataset directory, each script has a directory (e.g. `dataset1_script_name1`). Within a script's directory is a `prov.json` file which contains the provenance graph, and three directories. The most important one for this dataset is the `scripts` directory which contains the script we collected provenance from, and any scripts the original one called (`source`d in R lingo). \n",
    "For this analysis, the run_log.csv files and get_prov.RData files in a dataset's directory can be ignored as they are artifacts from the RaaS evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-provision",
   "metadata": {},
   "source": [
    "## Preprocessing the Raw Data into a Table\n",
    "\n",
    "We preprocess this raw data to generate a table that collects information on the number of each node and edge type in the provenance graphs, as well as features like number of lines in the script. We can use this table to then generate aggregate statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "casual-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to search the file system, parallelize, and parse provenance. \n",
    "import os\n",
    "import ray\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob \n",
    "from provdebug import ProvParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nutritional-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wrote this analysis to execute in a Docker container created from the jupyter/scipy-notebook:4d9c9bd9ced0 image. Therefore, we know this will be the path to the data. \n",
    "# For running this analysis outside of this environment, the path will need to change. \n",
    "root_directory = \"/home/jovyan/work/\"\n",
    "\n",
    "# First we must walk through all the directories described above and find all the `prov.json` files\n",
    "json_files = [y for x in os.walk(root_directory) for y in glob(os.path.join(x[0], 'prov.json'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "instructional-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take the full file path to the script from a provenance file, and produced a correctly formatted DOI of the dataset the script belonged to\n",
    "def get_doi_from_script_name(dir_path):\n",
    "    doi = dir_path.split(\"/home/rstudio/\")[1]\n",
    "    doi = doi.split(\"/dataset/\")[0]\n",
    "    doi = doi.replace(\"-\", \":\", 1)\n",
    "    doi = doi.replace(\"-\", \"/\")\n",
    "    return(doi)\n",
    "\n",
    "# this function returns the number of lines from a script\n",
    "def get_num_of_lines(filename, change_encoding = False):\n",
    "    \n",
    "    # Some files aren't in the default encoding \n",
    "    if not change_encoding:\n",
    "        script_file = open(filename, \"r\")\n",
    "    else:\n",
    "        script_file =  open(filename, \"r\", encoding = \"latin1\")\n",
    "    lines = script_file.readlines()\n",
    "    script_file.close()\n",
    "    \n",
    "    # Only count lines with code in them \n",
    "    num_of_lines = len([line for line in lines if line != \"\\n\"])\n",
    "    \n",
    "    return(num_of_lines)\n",
    "    \n",
    "# This function will extract information about which external libraries and their functions are called in the R scripts\n",
    "# It returns a dictionary where the keys represent column names and the values the column values. \n",
    "# When this function is called it will be on many filenames which will later be combined into one dataframe\n",
    "@ray.remote\n",
    "def get_function_edge_data(filename):\n",
    "    # We wrote a provenance parser to allow easy access to the info stored in the json, it is intialized by passing the filepath to the prov.json\n",
    "    try:\n",
    "        prov_info = ProvParser.Parser(filename)\n",
    "    except:\n",
    "        return(\"Error in: \" + filename)\n",
    "    \n",
    "    # This dataframe maps function node names to library node names \n",
    "    # It uses node names, not names of the libraries or functions themselves (f1 -> l1, f7 -> l3, etc)\n",
    "    func_lib_df = prov_info.getFuncLib()\n",
    "    \n",
    "    # The eventual return value, declare it here as empty in case there are no functions and libraries\n",
    "    # so that the function will still return just the empty dict with correct keys\n",
    "    func_df = {\"library_name\":[], \"function_name\":[], \"script_name\":[], \"doi\":[]}\n",
    "    \n",
    "    # Check if there are even function library edges, if so collect that info\n",
    "    if \"collection\" in func_lib_df:\n",
    "        # Use the function labels from func_lib_df to index into the function node df and return the names of the functions the script called \n",
    "        func_names = prov_info.getFuncNodes().loc[func_lib_df[\"entity\"]][\"name\"].values\n",
    "        \n",
    "        # Use the library labels from func_lib_df to index into the library node df and return the names of the libraries the script called functions from\n",
    "        lib_names = prov_info.getLibs().loc[func_lib_df[\"collection\"]][\"name\"].values\n",
    "        \n",
    "        # Script name and doi to uniquely identify where a function -> library mapping originated from \n",
    "        script_name = os.path.basename(prov_info.getEnvironment().loc[\"script\"][0])\n",
    "        doi = get_doi_from_script_name(prov_info.getEnvironment().loc[\"script\"][0])\n",
    "        \n",
    "        # Combine into a dict to return and later be constructed into a dataframe\n",
    "        func_df[\"library_name\"] = lib_names\n",
    "        func_df[\"function_name\"] = func_names\n",
    "        func_df[\"script_name\"] = [script_name] * len(func_names)\n",
    "        func_df[\"doi\"] = [doi] * len(func_names)\n",
    "        \n",
    "    return(func_df)\n",
    "    \n",
    "# This function will take a provenance file and extract some summary information before returning a row for the aggregate table. \n",
    "@ray.remote\n",
    "def get_prov_info_from_file(filename):\n",
    "    \n",
    "    # We wrote a provenance parser to allow easy access to the info stored in the json, it is intialized by passing the filepath to the prov.json\n",
    "    try:\n",
    "        prov_info = ProvParser.Parser(filename)\n",
    "    except:\n",
    "        return(\"Error in: \" + filename)\n",
    "\n",
    "    # One feature we identify is number of lines in the original script\n",
    "    # Due to encoding errors, and the fact that the scripts directory can contain more than the original script,\n",
    "    # we need multiple ways to find this file. We use the following variable to do this. \n",
    "    script_name = os.path.basename(prov_info.getEnvironment().loc[\"script\"][0])\n",
    "    script_path = os.path.dirname(filename) + \"/scripts/\" + script_name\n",
    "    script_directory = os.path.dirname(filename) + \"/scripts/\"\n",
    "    \n",
    "    # If the script path exists, that's the original script and we can use it directly\n",
    "    if(os.path.exists(script_path)):\n",
    "        \n",
    "            # Sometimes there are encoding errors, and if it doesn't work with the default, \n",
    "            # we've found that `latin1` will work correctly\n",
    "            try:\n",
    "                num_of_lines = get_num_of_lines(script_path)\n",
    "            except UnicodeDecodeError:\n",
    "                num_of_lines = get_num_of_lines(script_path, change_encoding=True)\n",
    "                \n",
    "    else:\n",
    "        # The filename might not match correctly due to the way it was encoded in the provenance,\n",
    "        # but in all cases of this there should only be one file in the scripts directory, use that one\n",
    "        r_files = [y for x in os.walk(script_directory) for y in glob(os.path.join(x[0], '*.R'))]\n",
    "        if(len(r_files) == 1):\n",
    "            num_of_lines = get_num_of_lines(r_files[0])\n",
    "        # This was used during debugging, it should NOT execute now. If it does, the data is different or something is wrong \n",
    "        else:\n",
    "            print(\"Unsure about R files:\" + filename)\n",
    "            num_of_lines = 0\n",
    "        \n",
    "    # Create the row as a list. Later, we will pass the list of lists generate a DataFrame\n",
    "    prov_values = [get_doi_from_script_name(prov_info.getEnvironment().loc[\"script\"][0]), #doi\n",
    "        os.path.basename(prov_info.getEnvironment().loc[\"script\"][0]), #script_name\n",
    "        num_of_lines, #num_of_lines\n",
    "        False if prov_info.getDataNodes().empty else prov_info.getDataNodes().name.eq('error.msg').any(), #error\n",
    "        len(prov_info.getProcNodes()), #num_of_proc_nodes \n",
    "        len(prov_info.getDataNodes()), #num_of_data_nodes \n",
    "        len(prov_info.getLibs()), #num_of_libraries \n",
    "        len(prov_info.getFuncNodes()), #num_of_functions \n",
    "        len(prov_info.getProcData()), #num_of_pd_edges \n",
    "        len(prov_info.getDataProc()), #num_of_dp_edges \n",
    "        len(prov_info.getFuncProc())] #num_of_fp_edges\n",
    "\n",
    "    return(prov_values)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "clear-graduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:52:47,369\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.8</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.1</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.8', ray_version='2.0.1', ray_commit='03b6bc7b5a305877501110ec04710a9c57011479', address_info={'node_ip_address': '172.17.0.2', 'raylet_ip_address': '172.17.0.2', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-03_17-52-45_664058_4179/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-03_17-52-45_664058_4179/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-11-03_17-52-45_664058_4179', 'metrics_export_port': 59553, 'gcs_address': '172.17.0.2:57496', 'address': '172.17.0.2:57496', 'dashboard_agent_listen_port': 52365, 'node_id': '35234dfe39d0c22ab04281200dc3bf1aeaad615dd746018cd09354b7'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intialize the multithreading library so we can use all CPUs so this doesn't take forever\n",
    "ray.init(ignore_reinit_error=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "orange-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prov_results becomes a list of lists where each inner list is a row of the table\n",
    "# This will become the \"Aggregate Table\" described below\n",
    "prov_results = ray.get([get_prov_info_from_file.remote(json_file) for json_file in json_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "digital-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func_results_dicts becomes a list of dicts where the key is the column names and the values are the elements of that column\n",
    "# This will become the \"Function Table\" described below\n",
    "func_results_dicts = ray.get([get_function_edge_data.remote(json_file) for json_file in json_files])\n",
    "# Combine the dicts into a single dataframe\n",
    "func_results = pd.concat([pd.DataFrame(func_dict) for func_dict in func_results_dicts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "french-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No more multithreading after this point\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-patrick",
   "metadata": {},
   "source": [
    "## Aggregate Table\n",
    "\n",
    "The following cell will create the final table containing information on the graph elements for each provenance file, as well as metadata features. We write the completed table out to `prov_table.csv` in the `output` directory. \n",
    "\n",
    "The following table describes each feature in the table. For more information on the provenance terms, see the [W3C PROV_JSON description](https://www.w3.org/Submission/prov-json/) and the RDataTracker [Extended PROV-JSON](https://github.com/End-to-end-provenance/ExtendedProvJson/blob/master/JSON-format.md)\n",
    "\n",
    "| Feature | Description |\n",
    "|--------:|:------------|\n",
    "|doi      | Uniquely identifies each dataset, and can be used to find the original dataset on Dataverse|\n",
    "|script_name | The name of the script we collected provenance for |\n",
    "| num_of_lines | The number of lines in the original script |\n",
    "| error   | Boolean value indicating whether the script encountered an error during execution (True) or not (False)|\n",
    "| num_of_proc_nodes | The number of procedure nodes in the provenance graph |\n",
    "| num_of_data_nodes | The number of data nodes in the provenance graph |\n",
    "| num_of_libraries | The number of library nodes, i.e. the number of R packages loaded in the R environment while the script executed |\n",
    "| num_of_functions | The number of function nodes, i.e. the number of unique functions called from external libraries |\n",
    "| num_of_pd_edges | The number of procedure node to data node edges |\n",
    "| num_of_dp_edges | The number of data node to procedure node edges |\n",
    "| num_of_fp_edges | The number of function node to procedure edges |\n",
    "\n",
    "The table is formatted as follows:\n",
    "\n",
    "|    | doi                    | script_name                                                   |   num_of_lines | error   |   num_of_proc_nodes |   num_of_data_nodes |   num_of_libraries |   num_of_functions |   num_of_pd_edges |   num_of_dp_edges |   num_of_fp_edges |\n",
    "|---:|:-----------------------|:--------------------------------------------------------------|---------------:|:--------|--------------------:|--------------------:|-------------------:|-------------------:|------------------:|------------------:|------------------:|\n",
    "|  0 | doi:XX.XXXX/XXX/XXXXXX | script_name1.R                |            583 | True    |                  20 |                   9 |                 17 |                  2 |                 6 |                 8 |                 2 |\n",
    "|  1 | doi:XX.XXXX/XXX/XXXXXX | script_name2.R                                 |            258 | False    |                   4 |                   2 |                  9 |                  0 |                 2 |                 1 |                 0 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "occasional-syntax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_lines</th>\n",
       "      <th>num_of_proc_nodes</th>\n",
       "      <th>num_of_data_nodes</th>\n",
       "      <th>num_of_libraries</th>\n",
       "      <th>num_of_functions</th>\n",
       "      <th>num_of_pd_edges</th>\n",
       "      <th>num_of_dp_edges</th>\n",
       "      <th>num_of_fp_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11463.000000</td>\n",
       "      <td>11463.000000</td>\n",
       "      <td>11463.000000</td>\n",
       "      <td>11463.000000</td>\n",
       "      <td>11463.000000</td>\n",
       "      <td>11463.000000</td>\n",
       "      <td>11463.000000</td>\n",
       "      <td>11463.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>337.420309</td>\n",
       "      <td>34.392218</td>\n",
       "      <td>29.968158</td>\n",
       "      <td>14.993457</td>\n",
       "      <td>5.075547</td>\n",
       "      <td>27.453110</td>\n",
       "      <td>37.263195</td>\n",
       "      <td>17.673820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>777.592910</td>\n",
       "      <td>83.042793</td>\n",
       "      <td>111.256454</td>\n",
       "      <td>6.876395</td>\n",
       "      <td>8.038245</td>\n",
       "      <td>101.502168</td>\n",
       "      <td>123.474316</td>\n",
       "      <td>63.578517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>143.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>347.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31931.000000</td>\n",
       "      <td>3612.000000</td>\n",
       "      <td>6825.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>6824.000000</td>\n",
       "      <td>4626.000000</td>\n",
       "      <td>4155.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_of_lines  num_of_proc_nodes  num_of_data_nodes  num_of_libraries  \\\n",
       "count  11463.000000       11463.000000       11463.000000      11463.000000   \n",
       "mean     337.420309          34.392218          29.968158         14.993457   \n",
       "std      777.592910          83.042793         111.256454          6.876395   \n",
       "min        1.000000           3.000000           1.000000          8.000000   \n",
       "25%       66.000000           6.000000           1.000000          9.000000   \n",
       "50%      143.000000          12.000000           5.000000         13.000000   \n",
       "75%      347.000000          31.000000          26.000000         19.000000   \n",
       "max    31931.000000        3612.000000        6825.000000         69.000000   \n",
       "\n",
       "       num_of_functions  num_of_pd_edges  num_of_dp_edges  num_of_fp_edges  \n",
       "count      11463.000000     11463.000000     11463.000000     11463.000000  \n",
       "mean           5.075547        27.453110        37.263195        17.673820  \n",
       "std            8.038245       101.502168       123.474316        63.578517  \n",
       "min            0.000000         0.000000         0.000000         0.000000  \n",
       "25%            0.000000         1.000000         0.000000         0.000000  \n",
       "50%            1.000000         4.000000         2.000000         1.000000  \n",
       "75%            7.000000        22.500000        28.000000        13.000000  \n",
       "max           83.000000      6824.000000      4626.000000      4155.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the table \n",
    "column_names= [\"doi\",\"script_name\",\"num_of_lines\", \"error\", \"num_of_proc_nodes\", \"num_of_data_nodes\", \"num_of_libraries\", \"num_of_functions\", \"num_of_pd_edges\", \"num_of_dp_edges\", \"num_of_fp_edges\"]\n",
    "prov_df = pd.DataFrame(prov_results, columns = column_names)\n",
    "\n",
    "# No procedure nodes means the execution likely failed\n",
    "prov_df = prov_df[prov_df.num_of_proc_nodes != 0]\n",
    "\n",
    "# No data nodes is highly likely to have failed, or a script that only loads libraries\n",
    "prov_df = prov_df[prov_df.num_of_data_nodes != 0]\n",
    "\n",
    "# Our completed table, re-index and save it and print descriptive stats\n",
    "prov_df.index = range(0, len(prov_df))\n",
    "prov_df.to_csv(\"../output/prov_table.csv\")\n",
    "prov_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hired-lighting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_lines</th>\n",
       "      <th>num_of_proc_nodes</th>\n",
       "      <th>num_of_data_nodes</th>\n",
       "      <th>num_of_libraries</th>\n",
       "      <th>num_of_functions</th>\n",
       "      <th>num_of_pd_edges</th>\n",
       "      <th>num_of_dp_edges</th>\n",
       "      <th>num_of_fp_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.472352</td>\n",
       "      <td>57.816171</td>\n",
       "      <td>53.882526</td>\n",
       "      <td>14.410174</td>\n",
       "      <td>9.009093</td>\n",
       "      <td>50.223888</td>\n",
       "      <td>72.139101</td>\n",
       "      <td>34.314819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>697.267264</td>\n",
       "      <td>98.103454</td>\n",
       "      <td>134.264386</td>\n",
       "      <td>6.449837</td>\n",
       "      <td>9.434850</td>\n",
       "      <td>112.849417</td>\n",
       "      <td>169.106466</td>\n",
       "      <td>69.948031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>119.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>265.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31931.000000</td>\n",
       "      <td>1930.000000</td>\n",
       "      <td>5279.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>3530.000000</td>\n",
       "      <td>4626.000000</td>\n",
       "      <td>1536.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_of_lines  num_of_proc_nodes  num_of_data_nodes  num_of_libraries  \\\n",
       "count   4069.000000        4069.000000        4069.000000       4069.000000   \n",
       "mean     256.472352          57.816171          53.882526         14.410174   \n",
       "std      697.267264          98.103454         134.264386          6.449837   \n",
       "min        1.000000           3.000000           1.000000          9.000000   \n",
       "25%       53.000000          12.000000           7.000000          9.000000   \n",
       "50%      119.000000          28.000000          23.000000         12.000000   \n",
       "75%      265.000000          65.000000          60.000000         18.000000   \n",
       "max    31931.000000        1930.000000        5279.000000         69.000000   \n",
       "\n",
       "       num_of_functions  num_of_pd_edges  num_of_dp_edges  num_of_fp_edges  \n",
       "count       4069.000000      4069.000000      4069.000000      4069.000000  \n",
       "mean           9.009093        50.223888        72.139101        34.314819  \n",
       "std            9.434850       112.849417       169.106466        69.948031  \n",
       "min            0.000000         0.000000         0.000000         0.000000  \n",
       "25%            2.000000         6.000000         4.000000         2.000000  \n",
       "50%            6.000000        21.000000        25.000000        13.000000  \n",
       "75%           14.000000        56.000000        78.000000        37.000000  \n",
       "max           74.000000      3530.000000      4626.000000      1536.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive stats for only successful executions\n",
    "successful_prov = prov_df[prov_df.error == False]\n",
    "successful_prov.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-cornwall",
   "metadata": {},
   "source": [
    "# Function Table\n",
    "\n",
    "The following cell will create the final table containing information on which functions scripts call and the libraries they come from. We write the completed table out to `func_table.csv` in the `output` directory.\n",
    "\n",
    "The following table describes each feature in the function table. \n",
    "\n",
    "| Feature | Description |\n",
    "|--------:|:------------|\n",
    "|doi      | Uniquely identifies each dataset, and can be used to find the original dataset on Dataverse|\n",
    "|script_name | The name of the script we collected provenance for |\n",
    "| function_name   | The name of the function the script identified in script_name called |\n",
    "| library_name | The name of the library the function identified in function_name comes from |\n",
    "\n",
    "The table is formatted as follows:\n",
    "\n",
    "|    | doi                    | script_name                                                   |   function_name | library_name   |\n",
    "|---:|:-----------------------|:--------------------------------------------------------------|----------------:|:---------------|\n",
    "|  0 | doi:XX.XXXX/XXX/XXXXXX | script_name1.R                                                |            plot | graphics       |\n",
    "|  1 | doi:XX.XXXX/XXX/XXXXXX | script_name2.R                                                | install.packages| utils          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "impaired-candy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>script_name</th>\n",
       "      <th>function_name</th>\n",
       "      <th>library_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57887</td>\n",
       "      <td>57887</td>\n",
       "      <td>57887</td>\n",
       "      <td>57887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2830</td>\n",
       "      <td>6837</td>\n",
       "      <td>2609</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>doi:10.7910/DVN/VTUSLV</td>\n",
       "      <td>analysis.R</td>\n",
       "      <td>read.csv</td>\n",
       "      <td>ggplot2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>284</td>\n",
       "      <td>599</td>\n",
       "      <td>2524</td>\n",
       "      <td>17561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           doi script_name function_name library_name\n",
       "count                    57887       57887         57887        57887\n",
       "unique                    2830        6837          2609          670\n",
       "top     doi:10.7910/DVN/VTUSLV  analysis.R      read.csv      ggplot2\n",
       "freq                       284         599          2524        17561"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_results.index = range(0, len(func_results))\n",
    "func_results = func_results[[\"doi\", \"script_name\", \"function_name\", \"library_name\"]]\n",
    "\n",
    "func_results.to_csv(\"../output/func_table.csv\")\n",
    "\n",
    "func_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-ladder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
