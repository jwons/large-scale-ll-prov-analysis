{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vanilla-request",
   "metadata": {},
   "source": [
    "# Preprocessing for Analysis of Large-Scale Collection of Language-Level Provenance\n",
    "\n",
    "Using the service [RaaS](https://www.github.com/jwons/raas), we executed thousands of R scripts hosted on Harvard's Dataverse while collecting langauge-level provenance using the `rdtLite` variant of the [RDataTracker](https://www.github.com/End-to-end-provenance/RDataTracker) collection tool. This notebook takes that raw data and processes it to generate an aggregate table of information about all the scripts to help find trends and patterns in R scripts or their provenance. \n",
    "\n",
    "## Description of Raw Data\n",
    "\n",
    "The RaaS collection process resulted in ~100 GB of metadata we have stored in a directory ll-prov-data (not hosted on GitHub due to size). The directory structure is described below:\n",
    "```\n",
    "ðŸ“¦ll-prov-data\n",
    " â”£ ðŸ“‚dataset_name1_prov_data\n",
    " â”ƒ â”— ðŸ“‚prov_data\n",
    " â”ƒ â”ƒ â”£ ðŸ“‚dataset1_script_name1\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚data\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚debug\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚scripts\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”— ðŸ“œdataset1_script_name1.R\n",
    " â”ƒ â”ƒ â”ƒ â”— ðŸ“œprov.json\n",
    " â”ƒ â”ƒ â”£ ðŸ“‚dataset1_script_name2\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚data\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”£ ðŸ“œrecorded_text_data.txt\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”£ ðŸ“œrecorded_csv_data.csv\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚debug\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚scripts\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”— ðŸ“œdataset1_script_name2.R\n",
    " â”ƒ â”ƒ â”ƒ â”— ðŸ“œprov.json\n",
    " â”ƒ â”ƒ â”£ ðŸ“œget_prov.RData\n",
    " â”ƒ â”ƒ â”— ðŸ“œrun_log.csv\n",
    " â”£ ðŸ“‚dataset_name2_prov_data\n",
    " â”ƒ â”— ðŸ“‚prov_data\n",
    " â”ƒ â”ƒ â”£ ðŸ“‚dataset2_script_name1\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚data\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚debug\n",
    " â”ƒ â”ƒ â”ƒ â”£ ðŸ“‚scripts\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”— ðŸ“œdataset2_script_name1.R\n",
    " â”ƒ â”ƒ â”ƒ â”ƒ â”— ðŸ“œsourced_script.R \n",
    " â”ƒ â”ƒ â”ƒ â”— ðŸ“œprov.json\n",
    " â”ƒ â”ƒ â”£ ðŸ“œget_prov.RData\n",
    " â”ƒ â”ƒ â”— ðŸ“œrun_log.csv\n",
    " ```\n",
    " Dataverse hosts 'datasets' which contain artifacts from published research, in this context that means one or more scripts. Our raw data is split into this granularity, with a directory for the provenance of each dataset (e.g. `dataset_name1_prov_data`). Within the dataset directory, each script has a directory (e.g. `dataset1_script_name1`). Within a script's directory is a `prov.json` file which contains the provenance graph, and three directories. The most important one for this dataset is the `scripts` directory which contains the script we collected provenance from, and any scripts the original one called (`source`d in R lingo). \n",
    "For this analysis, the run_log.csv files and get_prov.RData files in a dataset's directory can be ignored as they are artifacts from the RaaS evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-arlington",
   "metadata": {},
   "source": [
    "## Preprocessing the Raw Data into a Table\n",
    "\n",
    "We preprocess this raw data to generate a table that collects information on the number of each node and edge type in the provenance graphs, as well as features like number of lines in the script. We can use this table to then generate aggregate statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "invisible-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to search the file system, parallelize, and parse provenance. \n",
    "import os\n",
    "import ray\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob \n",
    "from provdebug import ProvParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "returning-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wrote this analysis to execute in a Docker container created from the jupyter/scipy-notebook:4d9c9bd9ced0 image. Therefore, we know this will be the path to the data. \n",
    "# For running this analysis outside of this environment, the path will need to change. \n",
    "root_directory = \"/home/jovyan/work/\"\n",
    "\n",
    "# First we must walk through all the directories described above and find all the `prov.json` files\n",
    "json_files = [y for x in os.walk(root_directory) for y in glob(os.path.join(x[0], 'prov.json'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amateur-scott",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 19:43:42,619\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.8</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.8', ray_version='2.0.0', ray_commit='cba26cc83f6b5b8a2ff166594a65cb74c0ec8740', address_info={'node_ip_address': '172.17.0.2', 'raylet_ip_address': '172.17.0.2', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-10-20_19-43-40_909948_61159/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-10-20_19-43-40_909948_61159/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-10-20_19-43-40_909948_61159', 'metrics_export_port': 60396, 'gcs_address': '172.17.0.2:61856', 'address': '172.17.0.2:61856', 'dashboard_agent_listen_port': 52365, 'node_id': 'e0c90139ddf77d73ee577fdc52512a444f766c1f1dfcbe5f0f1b61b5'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function will take the full file path to the script from a provenance file, and produced a correctly formatted DOI of the dataset the script belonged to\n",
    "def get_doi_from_script_name(dir_path):\n",
    "    doi = dir_path.split(\"/home/rstudio/\")[1]\n",
    "    doi = doi.split(\"/dataset/\")[0]\n",
    "    doi = doi.replace(\"-\", \":\", 1)\n",
    "    doi = doi.replace(\"-\", \"/\")\n",
    "    return(doi)\n",
    "\n",
    "# This function will take a provenance file and extract some summary information before returning a row for the aggregate table. \n",
    "@ray.remote\n",
    "def get_prov_info_from_file(filename):\n",
    "    \n",
    "    # We wrote a provenance to allow easy access to the info stored in the json, it is intialized by passing the filepath to the prov.json\n",
    "    try:\n",
    "        prov_info = ProvParser.Parser(filename)\n",
    "    except:\n",
    "        return(\"Error in: \" + filename)\n",
    "\n",
    "    # One feature we identify is number of lines in the original script\n",
    "    # Due to encoding errors, and the fact that the scripts directory can contain more than the original script,\n",
    "    # we need multiple ways to find this file. We use the following variable to do this. \n",
    "    script_name = os.path.basename(prov_info.getEnvironment().loc[\"script\"][0])\n",
    "    script_path = os.path.dirname(filename) + \"/scripts/\" + script_name\n",
    "    script_directory = os.path.dirname(filename) + \"/scripts/\"\n",
    "    \n",
    "    # If the script path exists, that's the original script and we can use it directly\n",
    "    if(os.path.exists(script_path)):\n",
    "        \n",
    "            # Sometimes there are encoding errors, and if it doesn't work with the default, \n",
    "            # we've found that `latin1` will work correctly\n",
    "            try:\n",
    "                with open(script_path, \"r\") as script_file:\n",
    "                    num_of_lines = len(script_file.readlines())\n",
    "            except UnicodeDecodeError:\n",
    "                with open(script_path, \"r\",encoding=\"latin1\") as script_file:\n",
    "                    num_of_lines = len(script_file.readlines())\n",
    "                \n",
    "    else:\n",
    "        # The filename might not match correctly due to the way it was encoded in the provenance,\n",
    "        # but in all cases of this there should only be one file in the scripts directory, use that one\n",
    "        r_files = [y for x in os.walk(script_directory) for y in glob(os.path.join(x[0], '*.R'))]\n",
    "        if(len(r_files) == 1):\n",
    "            with open(r_files[0], \"r\") as script_file:\n",
    "                num_of_lines = len(script_file.readlines())\n",
    "        # This was used during debugging, it should NOT execute now. If it does, the data is different or something is wrong \n",
    "        else:\n",
    "            print(\"Unsure about R files:\" + filename)\n",
    "            num_of_lines = 0\n",
    "        \n",
    "    # Create the row as a list. Later, we will pass the list of lists generate a DataFrame\n",
    "    prov_values = [get_doi_from_script_name(prov_info.getEnvironment().loc[\"script\"][0]), #doi\n",
    "        os.path.basename(prov_info.getEnvironment().loc[\"script\"][0]), #script_name\n",
    "        num_of_lines, #num_of_lines\n",
    "        False if prov_info.getDataNodes().empty else prov_info.getDataNodes().name.eq('error.msg').any(), #error\n",
    "        len(prov_info.getProcNodes()), #num_of_proc_nodes \n",
    "        len(prov_info.getDataNodes()), #num_of_data_nodes \n",
    "        len(prov_info.getLibs()), #num_of_libraries \n",
    "        len(prov_info.getFuncNodes()), #num_of_functions \n",
    "        len(prov_info.getProcData()), #num_of_pd_edges \n",
    "        len(prov_info.getDataProc()), #num_of_dp_edges \n",
    "        len(prov_info.getFuncProc())] #num_of_fp_edges\n",
    "\n",
    "    return(prov_values)\n",
    "\n",
    "ray.init(ignore_reinit_error=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjusted-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all CPUs so this doesn't take forever\n",
    "# prov_results becomes a list of lists where each inner list is a row of the table\n",
    "prov_results = ray.get([get_prov_info_from_file.remote(json_file) for json_file in json_files])\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-italy",
   "metadata": {},
   "source": [
    "## Aggregate Table\n",
    "\n",
    "This table contains information on the graph elements for each provenance files, as well as metadata features. The following table describes each feature in the table. For more information on the provenance terms, see the [W3C PROV_JSON description](https://www.w3.org/Submission/prov-json/) and the RDataTracker [Extended PROV-JSON](https://github.com/End-to-end-provenance/ExtendedProvJson/blob/master/JSON-format.md)\n",
    "\n",
    "| Feature | Description |\n",
    "|--------:|:------------|\n",
    "|doi      | Uniquely identifies each dataset, and can be used to find the original dataset on Dataverse|\n",
    "|script_name | The name of the script we collected provenance for |\n",
    "| num_of_lines | The number of lines in the original script |\n",
    "| error   | Boolean value indicating whether the script encountered an error during execution (True) or not (False)|\n",
    "| num_of_proc_nodes | The number of procedure nodes in the provenance graph |\n",
    "| num_of_data_nodes | The number of data nodes in the provenance graph |\n",
    "| num_of_libraries | The number of library nodes, i.e. the number of R packages loaded in the R environment while the script executed |\n",
    "| num_of_functions | The number of function nodes, i.e. the number of unique functions called from external libraries |\n",
    "| num_of_pd_edges | The number of procedure node to data node edges |\n",
    "| num_of_dp_edges | The number of data node to procedure node edges |\n",
    "| num_of_fp_edges | The number of function node to procedure edges |\n",
    "\n",
    "The table should be formatted as follows:\n",
    "\n",
    "|    | doi                    | script_name                                                   |   num_of_lines | error   |   num_of_proc_nodes |   num_of_data_nodes |   num_of_libraries |   num_of_functions |   num_of_pd_edges |   num_of_dp_edges |   num_of_fp_edges |\n",
    "|---:|:-----------------------|:--------------------------------------------------------------|---------------:|:--------|--------------------:|--------------------:|-------------------:|-------------------:|------------------:|------------------:|------------------:|\n",
    "|  0 | doi:XX.XXXX/XXX/XXXXXX | script_name1.R                |            583 | True    |                  20 |                   9 |                 17 |                  2 |                 6 |                 8 |                 2 |\n",
    "|  1 | doi:XX.XXXX/XXX/XXXXXX | script_name2.R                                 |            258 | False    |                   4 |                   2 |                  9 |                  0 |                 2 |                 1 |                 0 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eligible-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the table \n",
    "column_names= [\"doi\",\"script_name\",\"num_of_lines\", \"error\", \"num_of_proc_nodes\", \"num_of_data_nodes\", \"num_of_libraries\", \"num_of_functions\", \"num_of_pd_edges\", \"num_of_dp_edges\", \"num_of_fp_edges\"]\n",
    "prov_metadata = pd.DataFrame(prov_results, columns = column_names)\n",
    "\n",
    "# No procedure nodes means the execution likely failed\n",
    "prov_metadata = prov_metadata[prov_metadata.num_of_proc_nodes != 0]\n",
    "\n",
    "# No data nodes is highly likely to have failed, or a script that only loads libraries\n",
    "prov_metadata = prov_metadata[prov_metadata.num_of_data_nodes != 0]\n",
    "\n",
    "# Our completed table, save it and print descriptive stats\n",
    "prov_metadata.to_csv(\"../output/prov_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collect-retention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_lines</th>\n",
       "      <th>num_of_proc_nodes</th>\n",
       "      <th>num_of_data_nodes</th>\n",
       "      <th>num_of_libraries</th>\n",
       "      <th>num_of_functions</th>\n",
       "      <th>num_of_pd_edges</th>\n",
       "      <th>num_of_dp_edges</th>\n",
       "      <th>num_of_fp_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "      <td>4069.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>306.944950</td>\n",
       "      <td>57.816171</td>\n",
       "      <td>53.882526</td>\n",
       "      <td>14.410174</td>\n",
       "      <td>9.009093</td>\n",
       "      <td>50.223888</td>\n",
       "      <td>72.139101</td>\n",
       "      <td>34.314819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>825.486803</td>\n",
       "      <td>98.103454</td>\n",
       "      <td>134.264386</td>\n",
       "      <td>6.449837</td>\n",
       "      <td>9.434850</td>\n",
       "      <td>112.849417</td>\n",
       "      <td>169.106466</td>\n",
       "      <td>69.948031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>146.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>318.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>38629.000000</td>\n",
       "      <td>1930.000000</td>\n",
       "      <td>5279.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>3530.000000</td>\n",
       "      <td>4626.000000</td>\n",
       "      <td>1536.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_of_lines  num_of_proc_nodes  num_of_data_nodes  num_of_libraries  \\\n",
       "count   4069.000000        4069.000000        4069.000000       4069.000000   \n",
       "mean     306.944950          57.816171          53.882526         14.410174   \n",
       "std      825.486803          98.103454         134.264386          6.449837   \n",
       "min        1.000000           3.000000           1.000000          9.000000   \n",
       "25%       67.000000          12.000000           7.000000          9.000000   \n",
       "50%      146.000000          28.000000          23.000000         12.000000   \n",
       "75%      318.000000          65.000000          60.000000         18.000000   \n",
       "max    38629.000000        1930.000000        5279.000000         69.000000   \n",
       "\n",
       "       num_of_functions  num_of_pd_edges  num_of_dp_edges  num_of_fp_edges  \n",
       "count       4069.000000      4069.000000      4069.000000      4069.000000  \n",
       "mean           9.009093        50.223888        72.139101        34.314819  \n",
       "std            9.434850       112.849417       169.106466        69.948031  \n",
       "min            0.000000         0.000000         0.000000         0.000000  \n",
       "25%            2.000000         6.000000         4.000000         2.000000  \n",
       "50%            6.000000        21.000000        25.000000        13.000000  \n",
       "75%           14.000000        56.000000        78.000000        37.000000  \n",
       "max           74.000000      3530.000000      4626.000000      1536.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive stats for only successful executions\n",
    "successful_prov = prov_metadata[prov_metadata.error == False]\n",
    "successful_prov.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-possibility",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
